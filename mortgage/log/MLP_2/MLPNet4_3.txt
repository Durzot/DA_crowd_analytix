Namespace(batch_size=256, criterion='cross_entropy', cuda=1, dropout_rate=None, lr=0.00078125, lr_decay_fact=2, lr_decay_freq=2, model_name='MLPNet4', model_type='MLP_2', momentum=0, n_classes=2, n_epoch=6, optimizer='adam', other_lim=0.005, random_state=0)

MLPNet4(
  (fc1): Linear(in_features=61, out_features=16, bias=True)
  (fc2): Linear(in_features=16, out_features=16, bias=True)
  (fc3): Linear(in_features=16, out_features=16, bias=True)
  (fc4): Linear(in_features=16, out_features=2, bias=True)
)
train labels [24495 24495]
test labels [1635 6124]

[train epoch 1/6] | loss 0.63008 | f1_macro 0.635 | time 2 min 55 sec
cat 0: [14765, 8142]
cat 1: [9730, 16353]
[test epoch 1/6] | loss 0.627 | f1_macro 0.552 | time 0 min 5 sec
cat 0: [763, 1918]
cat 1: [872, 4206]
[train epoch 2/6] | loss 0.53954 | f1_macro 0.722 | time 4 min 10 sec
cat 0: [17509, 6628]
cat 1: [6986, 17867]
[test epoch 2/6] | loss 0.632 | f1_macro 0.549 | time 0 min 11 sec
cat 0: [694, 1784]
cat 1: [941, 4340]
[train epoch 3/6] | loss 0.50765 | f1_macro 0.741 | time 4 min 33 sec
cat 0: [17409, 5598]
cat 1: [7086, 18897]
[test epoch 3/6] | loss 0.596 | f1_macro 0.551 | time 0 min 10 sec
cat 0: [538, 1348]
cat 1: [1097, 4776]
[train epoch 4/6] | loss 0.49849 | f1_macro 0.746 | time 3 min 20 sec
cat 0: [17299, 5242]
cat 1: [7196, 19253]
[test epoch 4/6] | loss 0.615 | f1_macro 0.554 | time 0 min 5 sec
cat 0: [608, 1516]
cat 1: [1027, 4608]
[train epoch 5/6] | loss 0.49282 | f1_macro 0.749 | time 3 min 38 sec
cat 0: [17337, 5094]
cat 1: [7158, 19401]
[test epoch 5/6] | loss 0.594 | f1_macro 0.55 | time 0 min 10 sec
cat 0: [512, 1279]
cat 1: [1123, 4845]
[train epoch 6/6] | loss 0.48952 | f1_macro 0.751 | time 3 min 8 sec
cat 0: [17292, 4976]
cat 1: [7203, 19519]
[test epoch 6/6] | loss 0.582 | f1_macro 0.546 | time 0 min 8 sec
cat 0: [456, 1149]
cat 1: [1179, 4975]
